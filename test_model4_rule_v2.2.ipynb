{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda3\\envs\\seq2seq\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text()\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1294\n",
      "Unique tokens in target (zh) vocabulary: 1949\n",
      "['whenever', 'a', 'creature', 'you', 'control', 'attacks', 'alone', ',', 'that', 'creature', 'gets', '+', '1', '/', '+', '1', 'until', 'end', 'of', 'turn', '.'] ['每当', '一个', '由', '你', '操控', '的', '生物', '单独', '攻击', '时', '，', '该', '生物', '得', '+', '1', '/', '+', '1', '直到', '回合', '结束', '。']\n",
      "['it', 'becomes', 'a', 'creature', 'again', 'if', 'it', \"'s\", 'not', 'attached', 'to', 'a', 'creature', '.'] ['如果', '它', '未', '结', '附于', '生物', '上', '，', '就', '会', '再度', '成为', '生物', '。']\n",
      "['choose', 'one', '—'] ['选择', '一', '项', '～']\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 4)\n",
    "TRG.build_vocab(train_data, min_freq = 4)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")\n",
    "\n",
    "for x in random.sample(list(train_data), 3):\n",
    "    print(x.src, x.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:('[torch.LongTensor of size 11x128]', '[torch.LongTensor of size 128]')\n",
      "\t[.trg]:[torch.LongTensor of size 28x128]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "tmp = next(iter(train_iterator))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model4.definition import Encoder, Attention, Decoder, Seq2Seq\n",
    "from models.model4.train import init_weights, train, evaluate\n",
    "from utils import count_parameters, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,758,045 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be saved to result/model4-rule-v2.2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/291 [00:36<28:36,  6.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m TRG_PAD_IDX \u001b[39m=\u001b[39m TRG\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstoi[TRG\u001b[39m.\u001b[39mpad_token]\n\u001b[0;32m      3\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[39m=\u001b[39m TRG_PAD_IDX)\n\u001b[1;32m----> 5\u001b[0m train_loop(model, optimizer, criterion, train, evaluate,\n\u001b[0;32m      6\u001b[0m            train_iterator, valid_iterator, \n\u001b[0;32m      7\u001b[0m            save_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresult/\u001b[39;49m\u001b[39m'\u001b[39;49m, file_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodel4-rule-v2.2.pt\u001b[39;49m\u001b[39m'\u001b[39;49m, load_before_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Desktop\\mtg-cards-translation\\utils\\__init__.py:39\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, optimizer, criterion, train, evaluate, train_iterator, valid_iterator, N_EPOCHS, CLIP, save_path, file_name, load_before_train)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m     37\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 39\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_iterator, optimizer, criterion, CLIP)\n\u001b[0;32m     40\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[0;32m     42\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32md:\\Desktop\\mtg-cards-translation\\models\\model4\\train.py:61\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m#trg = [(trg len - 1) * batch size]\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m#output = [(trg len - 1) * batch size, output dim]\u001b[39;00m\n\u001b[0;32m     59\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, trg)\n\u001b[1;32m---> 61\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     63\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), clip)\n\u001b[0;32m     65\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\seq2seq\\lib\\site-packages\\torch\\_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    248\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    249\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    254\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 255\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\Miniconda3\\envs\\seq2seq\\lib\\site-packages\\torch\\autograd\\__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> 147\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    148\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    149\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model4-rule-v2.2.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model4.definition import beam_search\n",
    "model.load_state_dict(torch.load('result/model4-rule-v2.2.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '-', '1', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '-', '1', '1', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "data = 'target creature gets - 1 / - 1 until end of turn .'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 355\n",
      "src: [whenever you cast an instant or sorcery spell , < 1 > gets + 2 / + 0 until end of turn . ] trg = [每当你施放瞬间或法术咒语时，<1>得+2/+0直到回合结束。]\n",
      "每当你施放瞬间或法术咒语时，<1>得+2/+0直到回合结束。<eos> \t[probability: 0.68745]\n",
      "每当你使用瞬间或法术咒语时，<1>得+2/+0直到回合结束。<eos> \t[probability: 0.17417]\n",
      "每当你施放瞬间或咒语时，<1>得+2/+0直到回合结束。<eos> \t[probability: 0.00862]\n",
      "\n",
      "src: [when < 0 > enters the battlefield , exile target creature an opponent controls until < 0 > leaves the battlefield . ] trg = [当<0>进战场时，放逐目标由对手操控的生物，直到<0>离开战场为止。]\n",
      "当<0>进战场时，放逐目标由对手操控的生物，直到<0>离开战场为止。<eos> \t[probability: 0.81881]\n",
      "当<0>进战场时，放逐目标由对手操控的生物，直到0>离开战场为止。<eos> \t[probability: 0.02603]\n",
      "当<0>进战场时，放逐目标由对手操控的生物，令<0>离开战场为止。<eos> \t[probability: 0.01527]\n",
      "\n",
      "src: [at the beginning of combat on your turn , create a < 9 > that 's a copy of target non creature < 1 > you control , except its name is mishra 's warform and it 's a 4 / 4 construct < 1 > creature in addition to its other types . ] trg = [在你回合的战斗开始时，派出一个<9>，其为目标由你操控之非生物<1>的复制品，但名称是米斯拉的战形械，为4/4组构体<1>生物，且仍具有原本类别。]\n",
      "在你回合的战斗开始时，派出一个<9>为目标由你操控之非<1>的复制品，但仍是传奇是是传奇的生物，仍是是4/4组构体<1>生物仍仍 \t[probability: 0.00000]\n",
      "在你回合的战斗开始时，派出一个<9>为目标由你操控之非<1>的复制品，但仍是传奇是是传奇的生物，仍是是4/4组构体<1>生物。仍 \t[probability: 0.00000]\n",
      "在你回合的战斗开始时，派出一个<9>为目标由你操控之非<1>的复制品，但仍是传奇是是传奇的生物，且仍是是4/4组构体<1>生物。 \t[probability: 0.00000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import show_samples\n",
    "long_data = [x for x in test_data.examples if len(x.src) > 20]\n",
    "print(f'Number of samples: {len(long_data)}')\n",
    "show_samples(long_data, T, n=3, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: d:\\Desktop\\mtg-cards-translation\\models\\card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['Gain', 'control', 'of', 'target', 'creature', 'with', 'mana', 'value', 'X', 'or', 'less.', 'If', 'X', 'is', '5', 'or', 'more,', 'create', 'a', 'token', \"that's\", 'a', 'copy', 'of', 'that', 'creature.'], 'trg': ['获得目标法术力值等于或小于X的生物之操控权。如果X等于或大于5，则派出一个衍生物，此衍生物为该生物的复制品。']}\n",
      "[after preprocess]:gain control of target creature with mana value x or less .\n",
      "[before postprocess]:获得目标总法术力费用等于或小于x的生物之操控权。\n",
      "[after preprocess]:if x is 5 or more , create a token that 's a copy of that creature .\n",
      "[before postprocess]:如果x等于或大于5，则将一个衍生物放进战场，此衍生物为该生物的复制品。\n",
      "获得目标总法术力费用等于或小于x的生物之操控权。 如果x等于或大于5，则将一个衍生物放进战场，此衍生物为该生物的复制品。\n",
      "\n",
      "{'src': ['Toxic', '1', '(Players', 'dealt', 'combat', 'damage', 'by', 'this', 'creature', 'also', 'get', 'a', 'poison', 'counter.)\\nOther', 'Rats', 'you', 'control', 'have', 'toxic', '1.\\nWhen', 'Karumonix', 'enters', 'the', 'battlefield,', 'look', 'at', 'the', 'top', 'five', 'cards', 'of', 'your', 'library.', 'You', 'may', 'reveal', 'any', 'number', 'of', 'Rat', 'cards', 'from', 'among', 'them', 'and', 'put', 'the', 'revealed', 'cards', 'into', 'your', 'hand.', 'Put', 'the', 'rest', 'on', 'the', 'bottom', 'of', 'your', 'library', 'in', 'a', 'random', 'order.'], 'trg': ['下毒1', '由你操控的其他老鼠具有下毒1。', '当卡鲁蒙进战场时，检视你牌库顶的五张牌。你可以展示其中任意数量的老鼠牌，并将所展示的牌置于你手上。将其余的牌以随机顺序置于你牌库底。']}\n",
      "[after preprocess]:<0> 1\n",
      "[before postprocess]:<0>1\n",
      "[after preprocess]:players dealt combat damage by this creature also get a poison counter .\n",
      "[before postprocess]:受此生物战斗伤害的牌手还会得到一个中毒指示物。\n",
      "[after preprocess]:other rats you control have <0> 1 .\n",
      "[before postprocess]:由你操控的其他秘耳具有<0>异能。\n",
      "[after preprocess]:when <0> enters the battlefield , look at the top five cards of your library .\n",
      "[before postprocess]:当<0>进战场时，检视你牌库顶的五张牌。\n",
      "[after preprocess]:you may reveal any number of rat cards from among them and put the revealed cards into your hand .\n",
      "[before postprocess]:你可以展示其中任意数量的<unk>，，并将其中的牌置于你手上。\n",
      "[after preprocess]:put the rest on the bottom of your library in a random order .\n",
      "[before postprocess]:将其余的牌以随机顺序置于你的牌库底。\n",
      "下毒1 受此生物战斗伤害的牌手还会得到一个中毒指示物。 由你操控的其他秘耳具有下毒异能。 当<karumonix>进战场时，检视你牌库顶的五张牌。 你可以展示其中任意数量的<unk>，，并将其中的牌置于你手上。 将其余的牌以随机顺序置于你的牌库底。\n",
      "\n",
      "{'src': ['You', 'may', 'play', 'lands', 'from', 'your', 'graveyard.\\n{T}:', 'Choose', 'target', 'nonland', 'permanent', 'card', 'in', 'your', 'graveyard.', 'If', 'you', \"haven't\", 'cast', 'a', 'spell', 'this', 'turn,', 'you', 'may', 'cast', 'that', 'card.', 'If', 'you', 'do,', 'you', \"can't\", 'cast', 'additional', 'spells', 'this', 'turn.', 'Activate', 'only', 'as', 'a', 'sorcery.'], 'trg': ['你可以从你的坟墓场中使用地牌。', '{T}：选择目标在你坟墓场中的非地永久物牌。如果你本回合中未施放过咒语，则你可以施放该牌。若你如此作，则你本回合中不能再施放咒语。只能于法术时机起动。']}\n",
      "[after preprocess]:you may play lands from your graveyard .\n",
      "[before postprocess]:你可以从你的坟墓场中使用地牌。\n",
      "[after preprocess]:{t} : choose target non land permanent card in your graveyard .\n",
      "[before postprocess]:{t}：选择目标在你坟墓场中的非地永久物牌。\n",
      "[after preprocess]:if you have n't cast a spell this turn , you may cast that card .\n",
      "[before postprocess]:如果你于本回合中，你施放的咒语，则你可以施放该牌。\n",
      "[after preprocess]:if you do , you ca n't cast additional spells this turn .\n",
      "[before postprocess]:若你如此作，则你本回合不能施放咒语咒语。\n",
      "[after preprocess]:activate only as a sorcery .\n",
      "[before postprocess]:只能于时机视同起动。\n",
      "你可以从你的坟墓场中使用地牌。 {t}：选择目标在你坟墓场中的非地永久物牌。 如果你于本回合中，你施放的咒语，则你可以施放该牌。 若你如此作，则你本回合不能施放咒语咒语。 只能于时机视同起动。\n",
      "\n",
      "{'src': ['When', 'Charforger', 'enters', 'the', 'battlefield,', 'create', 'a', '1/1', 'red', 'Phyrexian', 'Goblin', 'creature', 'token.\\nWhenever', 'another', 'creature', 'or', 'artifact', 'you', 'control', 'is', 'put', 'into', 'a', 'graveyard', 'from', 'the', 'battlefield,', 'put', 'an', 'oil', 'counter', 'on', 'Charforger.\\nRemove', 'three', 'oil', 'counters', 'from', 'Charforger:', 'Exile', 'the', 'top', 'card', 'of', 'your', 'library.', 'You', 'may', 'play', 'that', 'card', 'this', 'turn.'], 'trg': ['当焦锻兽进战场时，派出一个1/1红色非瑞人／鬼怪衍生生物。', '每当另一个由你操控的生物或神器从战场进入坟墓场时，在焦锻兽上放置一个烁油指示物。', '从焦锻兽上移去三个烁油指示物：放逐你的牌库顶牌。本回合中，你可以使用该牌。']}\n",
      "[after preprocess]:when <0> enters the battlefield , create a 1 / 1 red phyrexian goblin creature token .\n",
      "[before postprocess]:当<0>进战场时，将一个1/1红色<unk>衍生生物放进战场。\n",
      "[after preprocess]:whenever another creature or artifact you control is put into a graveyard from the battlefield , put an <1> counter on <0> .\n",
      "[before postprocess]:每当另一个由你操控的生物或神器从战场进入坟墓场时，在<0>上放置一个<1>指示物。\n",
      "[after preprocess]:remove three <1> counters from <0> : exile the top card of your library .\n",
      "[before postprocess]:从<0>上移去三个<1>指示物：放逐你的牌库顶牌。\n",
      "[after preprocess]:you may play that card this turn .\n",
      "[before postprocess]:本回合中，你可以使用该牌。\n",
      "当<charforger>进战场时，将一个1/1红色<unk>衍生生物放进战场。 每当另一个由你操控的生物或神器从战场进入坟墓场时，在<charforger>上放置一个烁油指示物。 从<charforger>上移去三个烁油指示物：放逐你的牌库顶牌。 本回合中，你可以使用该牌。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentencize(text: str):\n",
    "    ignore = {' ', '(', ')', '\\n'}\n",
    "    while len(text) and text[0] in ignore:\n",
    "        text = text[1:]\n",
    "    if len(text) == 0:\n",
    "        return []\n",
    "    \n",
    "    r = 0\n",
    "    delims = {'.', '\\n', '('}\n",
    "    ignore = False\n",
    "    while r < len(text):\n",
    "        if text[r] == '\\\"':\n",
    "            ignore = not ignore\n",
    "        if not ignore and text[r] in delims:\n",
    "            break\n",
    "        r += 1\n",
    "    \n",
    "    if r < len(text) and text[r] == '.':\n",
    "        return [text[:r + 1]] + sentencize(text[r + 1:])\n",
    "    return [text[:r]] + sentencize(text[r:])\n",
    "def preprocess(x:str):\n",
    "    x = D.annotate(x).removeprefix(' ')\n",
    "    print(f'[after preprocess]:{x}')\n",
    "    return x\n",
    "def postprocess(x:str):\n",
    "    return x.replace('<', '').replace('>', '')\n",
    "\n",
    "import re\n",
    "class CTHelper:\n",
    "    def __init__(self, name_detector, dictionary={}) -> None:\n",
    "        self.D = name_detector\n",
    "        self.dictionary = dictionary\n",
    "    \n",
    "    def preprocess(self, x:str):\n",
    "        self.tag2str = {}\n",
    "        x = D.annotate(x).removeprefix(' ') # x become lowercase after go through detector\n",
    "        m = re.search('<[^0-9>]+>', x)\n",
    "        id = 0\n",
    "        while m:\n",
    "            l, r = m.span()\n",
    "            tag = '<' + str(id) + '>'\n",
    "            self.tag2str[tag] = x[l:r]\n",
    "            x = x[:l] + tag + x[r:]\n",
    "            id += 1\n",
    "            m = re.search('<[^0-9>]+>', x)\n",
    "\n",
    "        for s in self.dictionary.keys():\n",
    "            m = re.search(s, x)\n",
    "            if m:\n",
    "                tag = '<' + str(id) + '>'\n",
    "                self.tag2str[tag] = s\n",
    "                x = x.replace(s, tag)\n",
    "                id += 1\n",
    "\n",
    "        print(f'[  after preprocess]:{x}')\n",
    "        return x\n",
    "\n",
    "    def postprocess(self, x:str):\n",
    "        print(f'[before postprocess]:{x}')\n",
    "        for tag, s in self.tag2str.items():\n",
    "            x = x.replace(tag, self.dictionary[s] if s in self.dictionary else s)\n",
    "        return x\n",
    "\n",
    "dic = {}\n",
    "dic = {'oil':'烁油', 'rebel':'反抗军','compleated':'完化','multicolored':'多色','toxic':'下毒'}\n",
    "helper = CTHelper(D, dic)\n",
    "CT = CardTranslator(sentencize, T, preprocess=lambda x: helper.preprocess(x), postprocess=lambda x:helper.postprocess(x))\n",
    "\n",
    "example = random.sample(list(test_data), 1)[0]\n",
    "example = list(test_data)[237]\n",
    "print(vars(example))\n",
    "ret=CT.translate(' '.join(example.src))\n",
    "print(ret+'\\n')\n",
    "for example in random.sample(list(test_data), 3):\n",
    "    print(vars(example))\n",
    "    ret = CT.translate(' '.join(example.src))\n",
    "    print(ret + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6877907101188122"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
