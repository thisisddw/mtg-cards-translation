{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda3\\envs\\seq2seq\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text()\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1294\n",
      "Unique tokens in target (zh) vocabulary: 1949\n",
      "['flash'] ['flash']\n",
      "['<', '7', '>'] ['<', '7', '>']\n",
      "['whenever', 'another', 'creature', 'dies', ',', 'put', 'two', '+', '1', '/', '+', '1', 'counters', 'on', '<', '4', '>', '.'] ['每当', '另', '一个', '生物', '死去', '时', '，', '在', '<', '4', '>', '上', '放置', '两', '个', '+', '1', '/', '+', '1', '指示物', '。']\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 4)\n",
    "TRG.build_vocab(train_data, min_freq = 4)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")\n",
    "\n",
    "for x in random.sample(list(train_data), 3):\n",
    "    print(x.src, x.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:('[torch.LongTensor of size 29x128]', '[torch.LongTensor of size 128]')\n",
      "\t[.trg]:[torch.LongTensor of size 40x128]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "tmp = next(iter(train_iterator))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model4.definition import Encoder, Attention, Decoder, Seq2Seq\n",
    "from models.model4.train import init_weights, train, evaluate\n",
    "from utils import count_parameters, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,758,045 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model4-rule-v2.2.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model4.definition import beam_search\n",
    "model.load_state_dict(torch.load('result/model4-rule-v2.2.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)\n",
    "torch.save(T,'result/model4-T-v2.2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '-', '1', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '-', '1', '1', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "data = 'target creature gets - 1 / - 1 until end of turn .'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 355\n",
      "src: [at the beginning of your next upkeep , you may cast this card from exile without paying its mana cost . ] trg = [在你的下一个维持开始时，你可以从放逐区施放此牌，且不须支付其法术力费用。]\n",
      "在你的下一个维持开始时，你可以从放逐区施放此牌，且不需支付其法术力费用。<eos> \t[probability: 0.63112]\n",
      "在你的下一个维持开始时，你可以从放逐区施放此牌，且不须支付其法术力费用。<eos> \t[probability: 0.14685]\n",
      "在你下一个维持开始时，你可以从放逐区施放此牌，且不需支付其法术力费用。<eos> \t[probability: 0.03197]\n",
      "\n",
      "src: [whenever a creature enters the battlefield under an opponent 's control , you may attach < 6 > to that creature . ] trg = [每当一个生物在对手的操控下进场时，你可以将<6>结附在该生物上。]\n",
      "每当一个生物在对手的操控下进战场时，你可以将<6>装备在该生物上。<eos> \t[probability: 0.06546]\n",
      "每当一个生物在对手的操控下进战场时，你可以将<6>在该生物上。<eos> \t[probability: 0.06375]\n",
      "每当一个生物在对手的操控下进战场时，你可以将<6>对该生物上。<eos> \t[probability: 0.05898]\n",
      "\n",
      "src: [non - horror creatures with slime counters on them lose all abilities and have base power and toughness 2 / 2 . ] trg = [所有其上有黏菌指示物的非惊惧兽生物都失去所有异能，且基础力量与防御力均为2/2。]\n",
      "由其上有且其上有指示物的生物均失去所有异能与防御力为2/2。<eos> \t[probability: 0.00012]\n",
      "由其上有且其上有指示物的生物均失去所有基础力量与防御力为2/2。<eos> \t[probability: 0.00012]\n",
      "由其上有且其上有指示物的生物均失去所有异能，且基础力量与防御力为2/2。<eos> \t[probability: 0.00006]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import show_samples\n",
    "long_data = [x for x in test_data.examples if len(x.src) > 20]\n",
    "print(f'Number of samples: {len(long_data)}')\n",
    "show_samples(long_data, T, n=3, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: d:\\Desktop\\mtg-cards-translation\\models\\card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['Gain', 'control', 'of', 'target', 'creature', 'with', 'mana', 'value', 'X', 'or', 'less.', 'If', 'X', 'is', '5', 'or', 'more,', 'create', 'a', 'token', \"that's\", 'a', 'copy', 'of', 'that', 'creature.'], 'trg': ['获得目标法术力值等于或小于X的生物之操控权。如果X等于或大于5，则派出一个衍生物，此衍生物为该生物的复制品。']}\n",
      "获得目标总法术力费用等于或小于x的生物之操控权。 如果x等于或大于5，则将一个衍生物放进战场，此衍生物为该生物的复制品。\n",
      "\n",
      "{'src': ['For', 'Mirrodin!', '(When', 'this', 'Equipment', 'enters', 'the', 'battlefield,', 'create', 'a', '2/2', 'red', 'Rebel', 'creature', 'token,', 'then', 'attach', 'this', 'to', 'it.)\\nEquipped', 'creature', 'gets', '+2/+1', 'and', 'has', 'vigilance.\\nEquip', '{3}{W}', '({3}{W}:', 'Attach', 'to', 'target', 'creature', 'you', 'control.', 'Equip', 'only', 'as', 'a', 'sorcery.)'], 'trg': ['秘罗万岁！（当此武具进战场时，派出一个2/2红色反抗军衍生生物，然后将它贴附于其上。）', '佩带此武具的生物得+2/+1且具有警戒异能。', '佩带{3}{W}（{3}{W}：贴附在目标由你操控的生物上。只能于法术时机佩带。）']}\n",
      "<unk><unk><unk><unk>融合。 当此武具进战场时，将一个2/2红色反抗军衍生生物放进战场，然后将它装备上去。 佩带此武具的生物得+2/+1且具有警戒异能。 佩带{3}{w} {3}{w}：装备在目标由你操控的生物上。 佩带的时机视同法术。\n",
      "\n",
      "{'src': ['Trample\\nExuberant', 'Fuseling', 'gets', '+1/+0', 'for', 'each', 'oil', 'counter', 'on', 'it.\\nWhen', 'Exuberant', 'Fuseling', 'enters', 'the', 'battlefield', 'and', 'whenever', 'another', 'creature', 'or', 'artifact', 'you', 'control', 'is', 'put', 'into', 'a', 'graveyard', 'from', 'the', 'battlefield,', 'put', 'an', 'oil', 'counter', 'on', 'Exuberant', 'Fuseling.'], 'trg': ['践踏', '亢奋引火怪上每有一个烁油指示物，便得+1/+0。', '当亢奋引火怪进战场和每当另一个由你操控的生物或神器从战场进入坟墓场时，在亢奋引火怪上放置一个烁油指示物。']}\n",
      "践踏 <exuberant fuseling>上每有一个1指示物，<exuberant fuseling>便得+1/+0。 当<exuberant fuseling>进战场和另一个由你操控的生物或神器从战场进入战场时，在<exuberant fuseling>上放置一个烁油指示物。\n",
      "\n",
      "{'src': ['Flying,', 'vigilance\\nWhen', \"Malcator's\", 'Watcher', 'dies,', 'draw', 'a', 'card.'], 'trg': ['飞行，警戒', '当麻卡特的看守械死去时，抓一张牌。']}\n",
      "飞行，警戒 当<malcator 's watcher>从战场进入坟墓场时，抓一张牌。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentencize(text: str):\n",
    "    ignore = {' ', '(', ')', '\\n'}\n",
    "    while len(text) and text[0] in ignore:\n",
    "        text = text[1:]\n",
    "    if len(text) == 0:\n",
    "        return []\n",
    "    \n",
    "    r = 0\n",
    "    delims = {'.', '\\n', '('}\n",
    "    ignore = False\n",
    "    while r < len(text):\n",
    "        if text[r] == '\\\"':\n",
    "            ignore = not ignore\n",
    "        if not ignore and text[r] in delims:\n",
    "            break\n",
    "        r += 1\n",
    "    \n",
    "    if r < len(text) and text[r] == '.':\n",
    "        return [text[:r + 1]] + sentencize(text[r + 1:])\n",
    "    return [text[:r]] + sentencize(text[r:])\n",
    "def preprocess(x:str):\n",
    "    x = D.annotate(x).removeprefix(' ')\n",
    "    print(f'[after preprocess]:{x}')\n",
    "    return x\n",
    "def postprocess(x:str):\n",
    "    return x.replace('<', '').replace('>', '')\n",
    "\n",
    "import re\n",
    "class CTHelper:\n",
    "    def __init__(self, name_detector, dictionary={}) -> None:\n",
    "        self.D = name_detector\n",
    "        self.dictionary = dictionary\n",
    "    \n",
    "    def preprocess(self, x:str):\n",
    "        self.tag2str = {}\n",
    "        x = D.annotate(x).removeprefix(' ') # x become lowercase after go through detector\n",
    "        m = re.search('<[^0-9>]+>', x)\n",
    "        id = 0\n",
    "        while m:\n",
    "            l, r = m.span()\n",
    "            tag = '<' + str(id) + '>'\n",
    "            self.tag2str[tag] = x[l:r]\n",
    "            x = x[:l] + tag + x[r:]\n",
    "            id += 1\n",
    "            m = re.search('<[^0-9>]+>', x)\n",
    "\n",
    "        for s in self.dictionary.keys():\n",
    "            m = re.search(s, x)\n",
    "            if m:\n",
    "                tag = '<' + str(id) + '>'\n",
    "                self.tag2str[tag] = s\n",
    "                x = x.replace(s, tag)\n",
    "                id += 1\n",
    "\n",
    "        #print(f'[  after preprocess]:{x}')\n",
    "        return x\n",
    "\n",
    "    def postprocess(self, x:str):\n",
    "        #print(f'[before postprocess]:{x}')\n",
    "        for tag, s in self.tag2str.items():\n",
    "            x = x.replace(tag, self.dictionary[s] if s in self.dictionary else s)\n",
    "        return x\n",
    "\n",
    "dic = {}\n",
    "dic = {'oil':'烁油', 'rebel':'反抗军','compleated':'完化'}\n",
    "helper = CTHelper(D, dic)\n",
    "CT = CardTranslator(sentencize, T, preprocess=lambda x: helper.preprocess(x), postprocess=lambda x:helper.postprocess(x))\n",
    "\n",
    "example = random.sample(list(test_data), 1)[0]\n",
    "example = list(test_data)[237]\n",
    "print(vars(example))\n",
    "ret=CT.translate(' '.join(example.src))\n",
    "print(ret+'\\n')\n",
    "for example in random.sample(list(test_data), 3):\n",
    "    print(vars(example))\n",
    "    ret = CT.translate(' '.join(example.src))\n",
    "    print(ret + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6877907101188122"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
