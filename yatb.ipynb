{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yatb - yet another test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddw\\Anaconda3\\envs\\seq2seq\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models.model6 as model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text(include_lengths=False, batch_first=True)\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1475\n",
      "Unique tokens in target (zh) vocabulary: 2306\n",
      "['at', 'the', 'beginning', 'of', 'each', 'opponent', \"'s\", 'end', 'step', ',', 'that', 'player', 'creates', 'a', '1', '/', '1', 'red', 'goblin', 'creature', 'token', 'with', '\"', 'creatures', 'you', 'control', 'attack', 'each', 'combat', 'if', 'able', '.', '\"'] ['在', '每', '位', '对手', '的', '结束', '步骤', '开始', '时', '，', '该', '牌手', '派出', '一个', '1', '/', '1', '红色', '鬼怪', '衍生', '生物', '，', '且', '具有', '\"由', '你', '操控', '的', '生物', '每次', '战斗', '若', '能', '攻击', '，', '则', '必须', '攻击', '。', '\"']\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")\n",
    "\n",
    "for x in random.sample(list(train_data), 1):\n",
    "    print(x.src, x.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 128x14]\n",
      "\t[.trg]:[torch.LongTensor of size 128x24]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "print(next(iter(train_iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameters from d:\\ddw\\school\\大三下\\语音信息处理技术\\期末作业\\code\\mtg-cards-translation\\models\\model6/configs/default.json\n",
      "Parameters: {'HID_DIM': 256, 'ENC_LAYERS': 3, 'DEC_LAYERS': 3, 'ENC_HEADS': 8, 'DEC_HEADS': 8, 'ENC_PF_DIM': 512, 'DEC_PF_DIM': 512, 'ENC_DROPOUT': 0.1, 'DEC_DROPOUT': 0.1}\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = model6.create_model(INPUT_DIM, OUTPUT_DIM, SRC_PAD_IDX, TRG_PAD_IDX, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5565442"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import count_parameters, train_loop\n",
    "from models.model6.train import initialize_weights, train, evaluate\n",
    "model.apply(initialize_weights)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model6-rule-v2.1.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model6.definition import beam_search\n",
    "model.load_state_dict(torch.load('result/model6-rule-v2.1.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '结附于', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['直到', '回合', '结束', '，', '目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "data = 'target creature gets - 1 / - 1 until end of turn .'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: d:\\ddw\\school\\大三下\\语音信息处理技术\\期末作业\\code\\mtg-cards-translation\\models\\card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator, CTHelper\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['At', 'the', 'beginning', 'of', 'combat', 'on', 'your', 'turn,', 'target', 'creature', 'you', 'control', 'gets', '+1/+1', 'until', 'end', 'of', 'turn.', 'If', 'that', 'creature', 'has', 'toxic,', 'instead', 'it', 'gets', '+2/+2', 'until', 'end', 'of', 'turn.'], 'trg': ['在你回合的战斗开始时，目标由你操控的生物得+1/+1直到回合结束。若该生物具有下毒异能，则改为它得+2/+2直到回合结束。']}\n",
      "[after preprocess]:at the beginning of combat on your turn , target creature you control gets + 1 / + 1 until end of turn .\n",
      "[before postprocess]:在你回合的战斗开始时，目标由你操控的生物得+1/+1直到回合结束。\n",
      "[after preprocess]:if that creature has toxic , instead it gets + 2 / + 2 until end of turn .\n",
      "[before postprocess]:如果该生物具有<unk>，则改为该生物得+2/+2直到回合结束。\n",
      "在你回合的战斗开始时，目标由你操控的生物得+1/+1直到回合结束。 如果该生物具有<unk>，则改为该生物得+2/+2直到回合结束。\n",
      "{'src': ['For', 'Mirrodin!', '(When', 'this', 'Equipment', 'enters', 'the', 'battlefield,', 'create', 'a', '2/2', 'red', 'Rebel', 'creature', 'token,', 'then', 'attach', 'this', 'to', 'it.)\\nEquipped', 'creature', 'gets', '+1/-1.\\nEquip', '{1}', '({1}:', 'Attach', 'to', 'target', 'creature', 'you', 'control.', 'Equip', 'only', 'as', 'a', 'sorcery.)'], 'trg': ['秘罗万岁！（当此武具进战场时，派出一个2/2红色反抗军衍生生物，然后将它贴附于其上。）', '佩带此武具的生物得+1/-1。', '佩带{1}（{1}：贴附在目标由你操控的生物上。只能于法术时机佩带。）']}\n",
      "[after preprocess]:for <mirrodin !\n",
      "[before postprocess]:<unk><unk>\n",
      "[after preprocess]:when this equipment enters the battlefield , create a 2 / 2 red <0> creature token , then attach this to it .\n",
      "[before postprocess]:当此武具进战场时，派出一个2/2红色武具衍生生物，然后将<0>装备于其上。\n",
      "[after preprocess]:equipped creature gets + 1 / - 1 .\n",
      "[before postprocess]:佩带此武具的生物得+1/-1。\n",
      "[after preprocess]:equip {1}\n",
      "[before postprocess]:佩带{1}\n",
      "[after preprocess]:{1} : attach to target creature you control .\n",
      "[before postprocess]:{1}：装备在目标由你操控的生物上。\n",
      "[after preprocess]:equip only as a sorcery .\n",
      "[before postprocess]:只能于法术时机佩带。\n",
      "<unk><unk> 当此武具进战场时，派出一个2/2红色武具衍生生物，然后将反抗军装备于其上。 佩带此武具的生物得+1/-1。 佩带{1} {1}：装备在目标由你操控的生物上。 只能于法术时机佩带。\n",
      "{'src': ['You', 'draw', 'two', 'cards', 'and', 'you', 'lose', '2', 'life.', 'Each', 'opponent', 'gets', 'a', 'poison', 'counter.'], 'trg': ['你抓两张牌且失去2点生命。每位对手各得到一个中毒指示物。']}\n",
      "[after preprocess]:you draw two cards and you lose 2 life .\n",
      "[before postprocess]:你抓两张牌且失去2点生命。\n",
      "[after preprocess]:each opponent gets a poison counter .\n",
      "[before postprocess]:每位对手各得到一个中毒指示物。\n",
      "你抓两张牌且失去2点生命。 每位对手各得到一个中毒指示物。\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "dic = {'oil':'烁油', 'rebel':'反抗军'}\n",
    "helper = CTHelper(D, dic)\n",
    "CT = CardTranslator(sentencize, T, \n",
    "                    preprocess=lambda x: helper.preprocess(x, False), \n",
    "                    postprocess=lambda x: helper.postprocess(x, False))\n",
    "\n",
    "example = list(test_data)[13]\n",
    "example = list(test_data)[8]\n",
    "# ret = CT.translate(' '.join(example.src))\n",
    "# print(ret)\n",
    "for example in random.sample(list(test_data), 3):\n",
    "    print(vars(example))\n",
    "    ret = CT.translate(' '.join(example.src))\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
