{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models.model6 as model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text(include_lengths=False, batch_first=True)\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1294\n",
      "Unique tokens in target (zh) vocabulary: 1949\n",
      "['flying', ',', 'vigilance'] ['飞行', '，', '警戒']\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 4)\n",
    "TRG.build_vocab(train_data, min_freq = 4)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")\n",
    "\n",
    "for x in random.sample(list(train_data), 1):\n",
    "    print(x.src, x.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.LongTensor of size 128x14]\n",
      "\t[.trg]:[torch.LongTensor of size 128x23]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "print(next(iter(train_iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameters from d:\\Desktop\\mtg-cards-translation\\models\\model6/configs/wide.json\n",
      "Parameters: {'HID_DIM': 512, 'ENC_LAYERS': 3, 'DEC_LAYERS': 3, 'ENC_HEADS': 8, 'DEC_HEADS': 8, 'ENC_PF_DIM': 1024, 'DEC_PF_DIM': 1024, 'ENC_DROPOUT': 0.1, 'DEC_DROPOUT': 0.1}\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = model6.create_model(INPUT_DIM, OUTPUT_DIM, SRC_PAD_IDX, TRG_PAD_IDX, device,\n",
    "                            config='wide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18534301"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import count_parameters, train_loop\n",
    "from models.model6.train import initialize_weights, train, evaluate\n",
    "model.apply(initialize_weights)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be saved to result/model6-rule-v2.2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 19s\n",
      "\tTrain Loss: 2.062 | Train PPL:   7.861\n",
      "\t Val. Loss: 0.686 |  Val. PPL:   1.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 19s\n",
      "\tTrain Loss: 0.566 | Train PPL:   1.761\n",
      "\t Val. Loss: 0.335 |  Val. PPL:   1.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 19s\n",
      "\tTrain Loss: 0.341 | Train PPL:   1.406\n",
      "\t Val. Loss: 0.256 |  Val. PPL:   1.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 19s\n",
      "\tTrain Loss: 0.256 | Train PPL:   1.292\n",
      "\t Val. Loss: 0.206 |  Val. PPL:   1.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 19s\n",
      "\tTrain Loss: 0.208 | Train PPL:   1.231\n",
      "\t Val. Loss: 0.174 |  Val. PPL:   1.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 19s\n",
      "\tTrain Loss: 0.178 | Train PPL:   1.195\n",
      "\t Val. Loss: 0.154 |  Val. PPL:   1.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 19s\n",
      "\tTrain Loss: 0.158 | Train PPL:   1.171\n",
      "\t Val. Loss: 0.146 |  Val. PPL:   1.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 19s\n",
      "\tTrain Loss: 0.142 | Train PPL:   1.152\n",
      "\t Val. Loss: 0.137 |  Val. PPL:   1.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 19s\n",
      "\tTrain Loss: 0.128 | Train PPL:   1.137\n",
      "\t Val. Loss: 0.136 |  Val. PPL:   1.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 19s\n",
      "\tTrain Loss: 0.120 | Train PPL:   1.128\n",
      "\t Val. Loss: 0.128 |  Val. PPL:   1.136\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model6-rule-v2.2.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model6.definition import beam_search\n",
    "model.load_state_dict(torch.load('result/model6-rule-v2.2.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '-', '1', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['直到', '回合', '结束', '，', '目标', '生物', '得', '-', '1', '/', '-', '1', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "data = 'target creature gets - 1 / - 1 until end of turn .'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: d:\\Desktop\\mtg-cards-translation\\models\\card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator, CTHelper\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['As', 'long', 'as', 'Mirran', 'Safehouse', 'is', 'on', 'the', 'battlefield,', 'it', 'has', 'all', 'activated', 'abilities', 'of', 'all', 'land', 'cards', 'in', 'all', 'graveyards.'], 'trg': ['只要秘罗避难屋在战场上，它便具有所有坟墓场中所有地牌的所有起动式异能。']}\n",
      "[after preprocess]:as long as <0> is on the battlefield , it has all activated abilities of all land cards in all graveyards .\n",
      "[before postprocess]:只要<0>在战场上，它便具有所有坟墓场中每张生物牌的所有起动式异能。\n",
      "只要<mirran safehouse>在战场上，它便具有所有坟墓场中每张生物牌的所有起动式异能。\n",
      "{'src': ['+2:', 'Search', 'your', 'library', 'for', 'a', 'basic', 'Mountain', 'card,', 'reveal', 'it,', 'put', 'it', 'into', 'your', 'hand,', 'then', 'shuffle.\\n−3:', 'Koth,', 'Fire', 'of', 'Resistance', 'deals', 'damage', 'to', 'target', 'creature', 'equal', 'to', 'the', 'number', 'of', 'Mountains', 'you', 'control.\\n−7:', 'You', 'get', 'an', 'emblem', 'with', '\"Whenever', 'a', 'Mountain', 'enters', 'the', 'battlefield', 'under', 'your', 'control,', 'this', 'emblem', 'deals', '4', 'damage', 'to', 'any', 'target.\"'], 'trg': ['+2：从你牌库中搜寻一张基本的山脉牌，展示该牌，将它置于你手上，然后洗牌。', '−3：志士烈火寇斯对目标生物造成伤害，其数量等同于由你操控的山脉数量。', '−7：你获得具有以下异能的徽记～「每当一个山脉在你的操控下进战场时，此徽记对任意一个目标造成4点伤害。」']}\n",
      "[after preprocess]:+ 2 : search your library for a basic mountain card , reveal it , put it into your hand , then shuffle .\n",
      "[before postprocess]:+2：从你的牌库中搜寻一张基本的山脉，展示该牌，将它置于你手上，然后将你的牌库洗牌。\n",
      "[after preprocess]:− 3 : <0> deals damage to target creature equal to the number of mountains you control .\n",
      "[before postprocess]:−3：<0>对目标生物造成伤害，其数量等同于由你操控的山脉数量。\n",
      "[after preprocess]:− 7 : you get an emblem with \" whenever a mountain enters the battlefield under your control , this emblem deals 4 damage to any target . \"\n",
      "[before postprocess]:−7：你获得具有\"每当一个山脉在你的操控下进战场时，此地对任意一个目标造成4点伤害。\"\n",
      "+2：从你的牌库中搜寻一张基本的山脉，展示该牌，将它置于你手上，然后将你的牌库洗牌。 −3：<koth , fire of resistance>对目标生物造成伤害，其数量等同于由你操控的山脉数量。 −7：你获得具有\"每当一个山脉在你的操控下进战场时，此地对任意一个目标造成4点伤害。\"\n",
      "{'src': ['For', 'Mirrodin!', '(When', 'this', 'Equipment', 'enters', 'the', 'battlefield,', 'create', 'a', '2/2', 'red', 'Rebel', 'creature', 'token,', 'then', 'attach', 'this', 'to', 'it.)\\nAs', 'long', 'as', \"it's\", 'your', 'turn,', 'equipped', 'creature', 'has', 'first', 'strike', 'and', 'trample.\\nEquip', '{2}{R}'], 'trg': ['秘罗万岁！（当此武具进战场时，派出一个2/2红色反抗军衍生生物，然后将它贴附于其上。）', '只要是在你的回合中，佩带此武具的生物便具有先攻与践踏异能。', '佩带{2}{R}']}\n",
      "[after preprocess]:for <mirrodin !\n",
      "[before postprocess]:<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "[after preprocess]:when this equipment enters the battlefield , create a 2 / 2 red <0> creature token , then attach this to it .\n",
      "[before postprocess]:当此生物进战场时，派出一个2/2红色<0>衍生生物，然后将<0>装备于其上。\n",
      "[after preprocess]:as long as it 's your turn , equipped creature has first strike and trample .\n",
      "[before postprocess]:只要是在你的回合中，佩带此武具的生物便具有先攻与践踏异能。\n",
      "[after preprocess]:equip {2} {r}\n",
      "[before postprocess]:佩带{2}{r}\n",
      "<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> 当此生物进战场时，派出一个2/2红色反抗军衍生生物，然后将反抗军装备于其上。 只要是在你的回合中，佩带此武具的生物便具有先攻与践踏异能。 佩带{2}{r}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "dic = {'oil':'烁油', 'rebel':'反抗军'}\n",
    "helper = CTHelper(D, dic)\n",
    "silent = False\n",
    "CT = CardTranslator(sentencize, T, \n",
    "                    preprocess=lambda x: helper.preprocess(x, silent), \n",
    "                    postprocess=lambda x: helper.postprocess(x, silent))\n",
    "\n",
    "example = list(test_data)[13]\n",
    "example = list(test_data)[8]\n",
    "# ret = CT.translate(' '.join(example.src))\n",
    "# print(ret)\n",
    "for example in random.sample(list(test_data), 3):\n",
    "    print(vars(example))\n",
    "    ret = CT.translate(' '.join(example.src))\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:50<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.652888170122143"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
