{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models.model6_1 as model6_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text(include_lengths=False, batch_first=True)\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1294\n",
      "Unique tokens in target (zh) vocabulary: 1949\n",
      "['when', '<', '1', '>', 'enters', 'the', 'battlefield', ',', 'any', 'player', 'may', 'sacrifice', 'a', 'land', '.'] ['当', '<', '1', '>', '进场', '时', '，', '任意', '牌手', '可以', '牺牲', '一个', '地', '。']\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 4)\n",
    "TRG.build_vocab(train_data, min_freq = 4)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")\n",
    "\n",
    "for x in random.sample(list(train_data), 1):\n",
    "    print(x.src, x.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 128x34 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 128x46 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "print(next(iter(train_iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameters from /gemini/code/models/model6_1/configs/default.json\n",
      "Parameters: {'HID_DIM': 256, 'ENC_LAYERS': 3, 'DEC_LAYERS': 3, 'ENC_HEADS': 8, 'DEC_HEADS': 8, 'ENC_PF_DIM': 512, 'DEC_PF_DIM': 512, 'ENC_DROPOUT': 0.1, 'DEC_DROPOUT': 0.1}\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = model6_1.create_model(INPUT_DIM, OUTPUT_DIM, SRC_PAD_IDX, TRG_PAD_IDX, device,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5284765"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import count_parameters, train_loop\n",
    "from models.model6.train import initialize_weights, train, evaluate\n",
    "model.apply(initialize_weights)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be saved to result/model6.1-rule-v2.2.pt\n",
      "load model parameters from result/model6.1-rule-v2.2.pt\n",
      "Val. Loss: 0.127 |  Val. PPL:   1.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:20<00:00, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 20s\n",
      "\tTrain Loss: 0.125 | Train PPL:   1.133\n",
      "\t Val. Loss: 0.129 |  Val. PPL:   1.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 19s\n",
      "\tTrain Loss: 0.112 | Train PPL:   1.119\n",
      "\t Val. Loss: 0.123 |  Val. PPL:   1.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 19s\n",
      "\tTrain Loss: 0.105 | Train PPL:   1.111\n",
      "\t Val. Loss: 0.118 |  Val. PPL:   1.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 19s\n",
      "\tTrain Loss: 0.102 | Train PPL:   1.107\n",
      "\t Val. Loss: 0.112 |  Val. PPL:   1.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:20<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 20s\n",
      "\tTrain Loss: 0.097 | Train PPL:   1.102\n",
      "\t Val. Loss: 0.109 |  Val. PPL:   1.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 19s\n",
      "\tTrain Loss: 0.086 | Train PPL:   1.090\n",
      "\t Val. Loss: 0.108 |  Val. PPL:   1.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 20s\n",
      "\tTrain Loss: 0.087 | Train PPL:   1.091\n",
      "\t Val. Loss: 0.103 |  Val. PPL:   1.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:20<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 20s\n",
      "\tTrain Loss: 0.081 | Train PPL:   1.084\n",
      "\t Val. Loss: 0.103 |  Val. PPL:   1.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:20<00:00, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 20s\n",
      "\tTrain Loss: 0.078 | Train PPL:   1.081\n",
      "\t Val. Loss: 0.109 |  Val. PPL:   1.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454/454 [00:19<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 19s\n",
      "\tTrain Loss: 0.076 | Train PPL:   1.079\n",
      "\t Val. Loss: 0.101 |  Val. PPL:   1.106\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model6.1-rule-v2.2.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model6.definition import beam_search\n",
    "model.load_state_dict(torch.load('result/model6.1-rule-v2.2.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['直到', '回合', '结束', '，', '目标', '生物', '得', '-', '1', '/', '-', '1', '。', '<eos>']\n",
      "['目标', '结附于', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "data = 'target creature gets - 1 / - 1 until end of turn .'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /gemini/code/models/card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator, CTHelper\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['Vigilance\\nIf', 'a', 'permanent', 'entering', 'the', 'battlefield', 'causes', 'a', 'triggered', 'ability', 'of', 'a', 'permanent', 'you', 'control', 'to', 'trigger,', 'that', 'ability', 'triggers', 'an', 'additional', 'time.\\nPermanents', 'entering', 'the', 'battlefield', \"don't\", 'cause', 'abilities', 'of', 'permanents', 'your', 'opponents', 'control', 'to', 'trigger.'], 'trg': ['警戒', '如果由你操控之永久物具有的触发式异能因永久物进战场而触发，则该异能额外触发一次。', '进战场的永久物不会触发由对手操控之永久物的异能。']}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'removeprefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mlist\u001b[39m(test_data), \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mvars\u001b[39m(example))\n\u001b[0;32m---> 15\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mCT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ret)\n",
      "File \u001b[0;32m/gemini/code/utils/translate.py:62\u001b[0m, in \u001b[0;36mCardTranslator.translate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sents:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess:\n\u001b[0;32m---> 62\u001b[0m         sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     sent, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msent_translator\u001b[38;5;241m.\u001b[39mtranslate(sent)\n\u001b[1;32m     64\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m helper \u001b[38;5;241m=\u001b[39m CTHelper(D, dic)\n\u001b[1;32m      4\u001b[0m silent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      5\u001b[0m CT \u001b[38;5;241m=\u001b[39m CardTranslator(sentencize, T, \n\u001b[0;32m----> 6\u001b[0m                     preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mhelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m      7\u001b[0m                     postprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: helper\u001b[38;5;241m.\u001b[39mpostprocess(x, silent))\n\u001b[1;32m      9\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(test_data)[\u001b[38;5;241m13\u001b[39m]\n\u001b[1;32m     10\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(test_data)[\u001b[38;5;241m8\u001b[39m]\n",
      "File \u001b[0;32m/gemini/code/utils/translate.py:79\u001b[0m, in \u001b[0;36mCTHelper.preprocess\u001b[0;34m(self, x, silent)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:\u001b[38;5;28mstr\u001b[39m, silent:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag2str \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 79\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremoveprefix\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# x become lowercase after go through detector\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     m \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<[^0-9>]+>\u001b[39m\u001b[38;5;124m'\u001b[39m, x)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'removeprefix'"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "dic = {'oil':'烁油', 'rebel':'反抗军'}\n",
    "helper = CTHelper(D, dic)\n",
    "silent = False\n",
    "CT = CardTranslator(sentencize, T, \n",
    "                    preprocess=lambda x: helper.preprocess(x, silent), \n",
    "                    postprocess=lambda x: helper.postprocess(x, silent))\n",
    "\n",
    "example = list(test_data)[13]\n",
    "example = list(test_data)[8]\n",
    "# ret = CT.translate(' '.join(example.src))\n",
    "# print(ret)\n",
    "for example in random.sample(list(test_data), 3):\n",
    "    print(vars(example))\n",
    "    ret = CT.translate(' '.join(example.src))\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:50<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.652888170122143"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
