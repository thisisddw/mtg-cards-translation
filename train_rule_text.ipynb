{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddw\\Anaconda3\\envs\\seq2seq\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text()\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 4991\n",
      "Unique tokens in target (zh) vocabulary: 2357\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 32]\n",
      "\t[.src]:('[torch.LongTensor of size 14x32]', '[torch.LongTensor of size 32]')\n",
      "\t[.trg]:[torch.LongTensor of size 20x32]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "tmp = next(iter(train_iterator))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model4.definition import Encoder, Attention, Decoder, Seq2Seq\n",
    "from models.model4.train import init_weights, train, evaluate\n",
    "from utils import count_parameters, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,540,469 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='tut4-model.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model4.definition import beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('result/tut4-model.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<cn>', '的', '力量', '和', '防御力', '各', '等', '同于', '以', '它', '放逐', '的', '牌', '数量', '。', '<eos>']\n",
      "['<cn>', '的', '力量', '和', '防御力', '各', '等', '同于', '它', '放逐', '之', '牌', '的', '数量', '。', '<eos>']\n",
      "['<cn>', '的', '力量', '和', '防御力', '各', '等', '同于', '以', '它', '放逐', '之', '牌', '的', '数量', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "ret = T.translate('Unlicensed Hearse’s power and toughness are each equal to the number of cards exiled with it.')\n",
    "print(*ret[0][:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 45\n",
      "src: [whenever basri 's lieutenant or another creature you control dies , if it had a + 1 / + 1 counter on it , create a 2 / 2 white knight creature token with vigilance . ] trg = [每当<cn>或另一个由你操控的生物死去时，若其上有+1/+1指示物，则派出一个2/2白色，具警戒异能的骑士衍生生物。]\n",
      "每当<cn>或另一个由你操控的生物死去时，若其上有+1/+1指示物，则派出一个2/2白色，具警戒异能的骑士衍生生物。<eos> \t[probability: 0.11363]\n",
      "每当<cn>或另一个由你操控的生物死去时，若其上有+1/+1指示物，则派出一个2/2白色，具警戒异能的吸血鬼衍生生物。<eos> \t[probability: 0.01553]\n",
      "每当<cn>或另一个由你操控的生物死去时，若其上有+1/+1指示物，则派出一个2/2白色，具警戒异能的2/2白色，具警戒异能的骑士衍生生物。<eos> \t[probability: 0.00253]\n",
      "\n",
      "src: [whenever ghost of ramirez depietro deals combat damage to a player , choose up to one target card in a graveyard that was discarded or put there from a library this turn . ] trg = [每当<cn>对任一牌手造成战斗伤害时，选择至多一张目标在坟墓场中的牌，且须为本回合中弃掉或从牌库进入该处者。]\n",
      "每当<cn>对任一牌手造成战斗伤害时，选择至多一张目标在坟墓场中的坟墓场，且在本回合中有一张牌。<eos> \t[probability: 0.00000]\n",
      "每当<cn>对任一牌手造成战斗伤害时，选择至多一张目标在坟墓场中的坟墓场，且在本回合中有一张牌在你手上。<eos> \t[probability: 0.00000]\n",
      "每当<cn>对任一牌手造成战斗伤害时，选择至多一张目标在坟墓场中的坟墓场，且在本回合中有一张牌在你手上。。<eos> \t[probability: 0.00000]\n",
      "\n",
      "src: [whenever you cast an enchantment spell , if you do n't control a creature named keimi , create keimi , a legendary 3 / 3 black and green frog creature token with \" whenever you cast an enchantment spell , each opponent loses 1 life and you gain 1 life . \" ] trg = [每当你施放结界咒语时，若你未操控名称为哇魅的生物，则派出传奇衍生生物哇魅，其为3/3，黑绿双色的蛙，且具有\"每当你施放结界咒语时，每位对手各失去1点生命且你获得1点生命。\"]\n",
      "每当你施放结界咒语时，若你未操控名称为哇魅的生物哇魅，则派出传奇衍生生物哇魅，，传奇为3/3黑色，黑绿双色，且具有\"每当你施放神器，且每位对手各 \t[probability: 0.00000]\n",
      "每当你施放结界咒语时，若你未操控名称为哇魅的生物哇魅，则派出传奇衍生生物哇魅，，传奇为3/3黑色，黑绿双色，且具有\"每当你施放一个神器，且每位对手 \t[probability: 0.00000]\n",
      "每当你施放结界咒语时，若你未操控名称为哇魅的生物哇魅，则派出传奇衍生生物哇魅，，传奇为3/3黑色，黑绿双色，且具有\"每当你施放神器生物，且每位对手 \t[probability: 0.00000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import show_samples\n",
    "long_data = [x for x in test_data.examples if len(x.src) > 30]\n",
    "print(f'Number of samples: {len(long_data)}')\n",
    "show_samples(long_data, T, n=3, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:06<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.36702387304524\n"
     ]
    }
   ],
   "source": [
    "from utils import calculate_bleu\n",
    "\n",
    "bleu = calculate_bleu(long_data, lambda x: T.translate(x, beam_size=3)[0][0])\n",
    "print(bleu*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
