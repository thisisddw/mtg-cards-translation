{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text()\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1475\n",
      "Unique tokens in target (zh) vocabulary: 2306\n",
      "['whenever', '<', '7', '>', 'is', 'dealt', 'damage', ',', 'it', 'deals', 'that', 'much', 'damage', 'to', 'target', 'player', '.'] ['每当', '<', '7', '>', '受到', '伤害', '时', '，', '它', '对', '目标', '牌手', '造成', '等量', '的', '伤害', '。']\n",
      "['as', 'you', 'cast', 'an', 'arcane', 'spell', ',', 'you', 'may', 'reveal', 'this', 'card', 'from', 'your', 'hand', 'and', 'pay', 'its', 'splice', 'cost', '.'] ['于', '你', '使用', '古咒', '咒语', '时', '，', '你', '可以', '从', '你', '手上', '展示', '此', '牌', '，', '并', '支付', '其', '通联', '费用', '。']\n",
      "['•', 'creatures', 'without', 'flying', 'ca', \"n't\", 'block', 'this', 'turn', '.'] ['•', '不', '具', '飞行', '异能', '的', '生物', '本', '回合', '不', '能', '进行', '阻挡', '。']\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")\n",
    "\n",
    "for x in random.sample(list(train_data), 3):\n",
    "    print(x.src, x.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:('[torch.LongTensor of size 8x128]', '[torch.LongTensor of size 128]')\n",
      "\t[.trg]:[torch.LongTensor of size 17x128]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "tmp = next(iter(train_iterator))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model4.definition import Encoder, Attention, Decoder, Seq2Seq\n",
    "from models.model4.train import init_weights, train, evaluate\n",
    "from utils import count_parameters, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,535,874 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model4-rule-v2.1.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model4.definition import beam_search\n",
    "model.load_state_dict(torch.load('result/model4-rule-v2.1.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['目标', '生物', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '得', '-', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n",
      "['目标', '生物', '得', '1', '/', '-', '1', '直到', '回合', '结束', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "data = 'target creature gets - 1 / - 1 until end of turn .'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 212\n",
      "src: [whenever one or more loyalty counters are removed from < 3 > , she deals that much damage to target opponent or planeswalker . ] trg = [每当从<3>上移去一个或数个忠诚指示物时，她向目标对手或鹏洛客造成等量的伤害。]\n",
      "每当一个<3>上移去一个或数个忠诚指示物时，刻拉诺斯对目标对手造成等量的伤害。<eos> \t[probability: 0.00182]\n",
      "每当一个<3>上移去一个或数个忠诚指示物时，普罗烽斯对目标对手造成等量的伤害。<eos> \t[probability: 0.00093]\n",
      "每当一个<3>上移去一个或数个忠诚指示物时，<unk>对目标对手造成等量的伤害。<eos> \t[probability: 0.00063]\n",
      "\n",
      "src: [when < 7 > enters the battlefield , exile up to one target artifact or creature until < 7 > leaves the battlefield . ] trg = [当<7>进战场时，放逐至多一个目标神器或生物，直到<7>离开战场为止。]\n",
      "当<7>进战场时，放逐至多一个目标神器或生物，直到<7>离开战场为止。<eos> \t[probability: 0.40705]\n",
      "当<7>进战场时，放逐至多一个目标神器或生物直到<7>离开战场为止。<eos> \t[probability: 0.03298]\n",
      "当<7>进战场时，放逐至多一个目标神器生物，直到<7>离开战场为止。<eos> \t[probability: 0.01970]\n",
      "\n",
      "src: [choose any number of permanents and / or players , then give each another counter of each kind already there . ] trg = [你选择任意数量其上有指示物的永久物和／或牌手，然后在其上放置一个它已有之类别的指示物。]\n",
      "选择任意数量的永久物和／或牌手，然后为其已有之每种指示物各多放置一个同类的指示物。<eos> \t[probability: 0.00896]\n",
      "你选择任意数量其上有指示物的永久物和／或牌手，然后在其已有之每种指示物各多放置一个同类的指示物。<eos> \t[probability: 0.00086]\n",
      "你选择任意数量其上有指示物的永久物和／或牌手，然后在其上放置一个它已有之类别的指示物。<eos> \t[probability: 0.00078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import show_samples\n",
    "long_data = [x for x in test_data.examples if len(x.src) > 20]\n",
    "print(f'Number of samples: {len(long_data)}')\n",
    "show_samples(long_data, T, n=3, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: d:\\ddw\\school\\大三下\\语音信息处理技术\\期末作业\\code\\mtg-cards-translation\\models\\card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['For', 'Mirrodin!', '(When', 'this', 'Equipment', 'enters', 'the', 'battlefield,', 'create', 'a', '2/2', 'red', 'Rebel', 'creature', 'token,', 'then', 'attach', 'this', 'to', 'it.)\\nEquipped', 'creature', 'gets', '+0/+1.\\nEquip', '{1}{W}', '({1}{W}:', 'Attach', 'to', 'target', 'creature', 'you', 'control.', 'Equip', 'only', 'as', 'a', 'sorcery.)'], 'trg': ['秘罗万岁！（当此武具进战场时，派出一个2/2红色反抗军衍生生物，然后将它贴附于其上。）', '佩带此武具的生物得+0/+1。', '佩带{1}{W}（{1}{W}：贴附在目标由你操控的生物上。只能于法术时机佩带。）']}\n",
      "[after preprocess]:for <mirrodin !\n",
      "[after preprocess]:when this equipment enters the battlefield , create a 2 / 2 red <0> creature token , then attach this to it .\n",
      "[after preprocess]:equipped creature gets + 0 / + 1 .\n",
      "[after preprocess]:equip {1} {w}\n",
      "[after preprocess]:{1} {w} : attach to target creature you control .\n",
      "[after preprocess]:equip only as a sorcery .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<unk><unk><unk><unk><unk> 当此武具进战场时，派出一个2/2红色，然后将它装备上去。 佩带此武具的生物得+0/+1。 佩带{1}{w} {1}{w}：贴附在目标由你操控的生物上。 只能于法术时机佩带。'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentencize(text: str):\n",
    "    ignore = {' ', '(', ')', '\\n'}\n",
    "    while len(text) and text[0] in ignore:\n",
    "        text = text[1:]\n",
    "    if len(text) == 0:\n",
    "        return []\n",
    "    \n",
    "    r = 0\n",
    "    delims = {'.', '\\n', '('}\n",
    "    ignore = False\n",
    "    while r < len(text):\n",
    "        if text[r] == '\\\"':\n",
    "            ignore = not ignore\n",
    "        if not ignore and text[r] in delims:\n",
    "            break\n",
    "        r += 1\n",
    "    \n",
    "    if r < len(text) and text[r] == '.':\n",
    "        return [text[:r + 1]] + sentencize(text[r + 1:])\n",
    "    return [text[:r]] + sentencize(text[r:])\n",
    "def preprocess(x:str):\n",
    "    x = D.annotate(x).removeprefix(' ')\n",
    "    print(f'[after preprocess]:{x}')\n",
    "    return x\n",
    "def postprocess(x:str):\n",
    "    return x.replace('<', '').replace('>', '')\n",
    "\n",
    "import re\n",
    "class CTHelper:\n",
    "    def __init__(self, name_detector, dictionary={}) -> None:\n",
    "        self.D = name_detector\n",
    "        self.dictionary = dictionary\n",
    "    \n",
    "    def preprocess(self, x:str):\n",
    "        self.tag2str = {}\n",
    "        x = D.annotate(x).removeprefix(' ') # x become lowercase after go through detector\n",
    "        m = re.search('<[^0-9>]+>', x)\n",
    "        id = 0\n",
    "        while m:\n",
    "            l, r = m.span()\n",
    "            tag = '<' + str(id) + '>'\n",
    "            self.tag2str[tag] = x[l:r]\n",
    "            x = x[:l] + tag + x[r:]\n",
    "            id += 1\n",
    "            m = re.search('<[^0-9>]+>', x)\n",
    "\n",
    "        for s in self.dictionary.keys():\n",
    "            m = re.search(s, x)\n",
    "            if m:\n",
    "                tag = '<' + str(id) + '>'\n",
    "                self.tag2str[tag] = s\n",
    "                x = x.replace(s, tag)\n",
    "                id += 1\n",
    "\n",
    "        print(f'[after preprocess]:{x}')\n",
    "        return x\n",
    "\n",
    "    def postprocess(self, x:str):\n",
    "        for tag, s in self.tag2str.items():\n",
    "            x = x.replace(tag, self.dictionary[s] if s in self.dictionary else s)\n",
    "        return x\n",
    "\n",
    "dic = {}\n",
    "dic = {'oil':'烁油', 'rebel':'反抗军'}\n",
    "helper = CTHelper(D, dic)\n",
    "CT = CardTranslator(sentencize, T, preprocess=lambda x: helper.preprocess(x), postprocess=lambda x:helper.postprocess(x))\n",
    "\n",
    "example = random.sample(list(test_data), 1)[0]\n",
    "example = list(test_data)[13]\n",
    "print(vars(example))\n",
    "CT.translate(' '.join(example.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:58<00:00,  1.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6487408865964257"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
