{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddw\\Anaconda3\\envs\\seq2seq\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text()\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1488\n",
      "Unique tokens in target (zh) vocabulary: 2313\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['假设', '中间', '夹', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', '着', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', '一个', '名字']\n",
      "['there', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', 'is', 'a', 'card', 'name', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', '.']\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import tokenize_en, tokenize_zh\n",
    "\n",
    "print(tokenize_zh('假设中间夹<xbp, the strongest of all>着<xbp, the strongest of all>一个名字'))\n",
    "print(tokenize_en('there <xbp, the strongest of all> is a card name <xbp, the strongest of all>.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:('[torch.LongTensor of size 40x128]', '[torch.LongTensor of size 128]')\n",
      "\t[.trg]:[torch.LongTensor of size 49x128]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "tmp = next(iter(train_iterator))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model4.definition import Encoder, Attention, Decoder, Seq2Seq\n",
    "from models.model4.train import init_weights, train, evaluate\n",
    "from utils import count_parameters, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,553,545 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model4-rule-v2.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model4.definition import beam_search\n",
    "model.load_state_dict(torch.load('model4-rule-v2.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['当', '你', '6', '}', '，', '牺牲', '<', 'v', 'i', 'n', 'd', 'i', 'c', 't', 'i', 'v', 'e', ' ', 'f', 'l', 'a', 'm', 'e', 's', 't', 'o', 'k', 'e', 'r', '>', '：', '弃掉', '你', '的', '手牌', '，', '然后', '抓', '四', '张', '牌', '。', '<eos>']\n",
      "['压印～', '{', '6', '}', 'r', 'r', 'c', 't', 'i', 'v', 'e', ' ', 'f', 'l', 'a', 'm', 'e', 's', 't', 'o', 'k', 'e', 'r', '>', '：', '弃掉', '你', '的', '手牌', '，', '然后', '抓', '四', '张', '牌', '。', '<eos>']\n",
      "['当', '你', '6', '}', '，', '牺牲', '<', 'v', 'i', 'n', 'd', 'i', 'c', 't', 'i', 'v', 'e', ' ', 'f', 'l', 'a', 'm', 'e', 's', 't', 'o', 'k', 'e', 'r', '>', '：', '弃掉', '你', '的', '手牌', '，', '然后', '抓', '四', '张', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'Whenever <1> becomes attached to a creature, for as long as <1> remains attached to it, you may have that creature become a copy of another target creature you control.'\n",
    "ret, prob = T.translate(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 352\n",
      "src: [tap any number of creatures you control with total power 3 or more : this vehicle becomes an artifact creature until end of turn . ] trg = [横置任意数量由你操控且力量总和等于或大于3的生物：此载具成为神器生物直到回合结束。]\n",
      "横置任意数量由你操控且力量总和等于或大于3的生物：此载具成为神器生物直到回合结束。<eos> \t[probability: 0.90875]\n",
      "横置任意数量由你操控且且力量总和等于或大于3的生物：此载具成为神器生物直到回合结束。<eos> \t[probability: 0.00535]\n",
      "横置任意数量由由你操控且力量总和等于或大于3的生物：此载具成为神器生物直到回合结束。<eos> \t[probability: 0.00473]\n",
      "\n",
      "src: [once during each of your turns , you may play a land or cast a permanent spell from among cards in your graveyard that were put there from your library this turn . ] trg = [仅于你的每个回合中且限一次，你可以从本回合自你牌库进入你坟墓场的牌之中使用一个地或施放一个永久物咒语。]\n",
      "对每个由你的每个回合中且限一次，你可以从你的坟墓场中施放一个由你坟墓场中施放咒语或永久物咒语。<eos> \t[probability: 0.00000]\n",
      "对每个由你的每个回合中且限一次，你可以从你的坟墓场中施放一个由你坟墓场中施放地咒语，你可以从你坟墓场中施放。<eos> \t[probability: 0.00000]\n",
      "对每个由你的每个回合中且限一次，你可以从你的坟墓场中施放一个由你坟墓场中施放地咒语，你可以从你坟墓场中施放咒语。<eos> \t[probability: 0.00000]\n",
      "\n",
      "src: [it 's an artifact with \" { t } , sacrifice this artifact : add one mana of any color . \" ] trg = [它是具有\"{t}，牺牲此神器：加一点任意颜色的法术力\"的神器。]\n",
      "珍宝衍生物是具有\"{t}，牺牲此神器：加一点任意颜色的法术力\"的神器。<eos> \t[probability: 0.55779]\n",
      "它是具有\"{t}，牺牲此神器：加一点任意颜色的法术力\"的神器。<eos> \t[probability: 0.11552]\n",
      "它生物是具有\"{t}，牺牲此神器：加一点任意颜色的法术力\"的神器。<eos> \t[probability: 0.05003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import show_samples\n",
    "long_data = [x for x in test_data.examples if len(x.src) > 20]\n",
    "print(f'Number of samples: {len(long_data)}')\n",
    "show_samples(long_data, T, n=3, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: d:\\ddw\\school\\大三下\\语音信息处理技术\\期末作业\\code\\mtg-cards-translation\\models\\card_name_detector\n"
     ]
    }
   ],
   "source": [
    "from dataset.mtgcards import TestSets\n",
    "from utils import calculate_bleu\n",
    "from torchtext.legacy.data import Field\n",
    "from models.card_name_detector.definition import TrainedDetector\n",
    "from utils.translate import sentencize, CardTranslator\n",
    "\n",
    "fields = {'src-rule': ('src', Field(tokenize=lambda x: x.split(' '))), 'trg-rule': ('trg', Field())}\n",
    "test_data = TestSets.load(fields)\n",
    "\n",
    "D = TrainedDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['Choose', 'one', '—\\n•', 'Charge', 'of', 'the', 'Mites', 'deals', 'damage', 'equal', 'to', 'the', 'number', 'of', 'creatures', 'you', 'control', 'to', 'target', 'creature', 'or', 'planeswalker.\\n•', 'Create', 'two', '1/1', 'colorless', 'Phyrexian', 'Mite', 'artifact', 'creature', 'tokens', 'with', 'toxic', '1', 'and', '\"This', 'creature', \"can't\", 'block.\"', '(Players', 'dealt', 'combat', 'damage', 'by', 'them', 'also', 'get', 'a', 'poison', 'counter.)'], 'trg': ['选择一项～', '•虫械冲锋对目标生物或鹏洛客造成伤害，其数量等同于由你操控的生物数量。', '•派出两个1/1无色非瑞人／虫械衍生神器生物，且具有下毒1与「此生物不能进行阻挡。」（受到其战斗伤害的牌手还会得到一个中毒指示物。）']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'再选择一项～ •<charge of the mites>对目标生物或鹏洛客造成伤害，其数量等同于由你操控的生物数量。 •派出两个1/1无色秘耳衍生神器生物，且具有下毒1且具有\"此生物不能进行阻挡。 闪现 将它们受过伤害的牌手还会得到一个中毒指示物。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(x:str):\n",
    "    x = D.annotate(x)\n",
    "    # print(f'[after preprocess]:{x}')\n",
    "    return x\n",
    "def postprocess(x:str):\n",
    "    return x.replace('<', '').replace('>', '')\n",
    "CT = CardTranslator(sentencize, T, preprocess=preprocess)\n",
    "\n",
    "example = random.sample(list(test_data), 1)[0]\n",
    "print(vars(example))\n",
    "CT.translate(' '.join(example.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.605499267578125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calculate_testset_bleu\n",
    "calculate_testset_bleu(list(test_data)[:100], CT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
