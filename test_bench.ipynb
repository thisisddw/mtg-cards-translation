{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from dataset.mtgcards import RuleText\n",
    "from utils.preprocess import fields_for_rule_text\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC, TRG = fields_for_rule_text()\n",
    "fields = {'src': ('src', SRC), 'trg': ('trg', TRG)}\n",
    "\n",
    "train_data, valid_data, test_data = RuleText.splits(fields=fields, version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (en) vocabulary: 1488\n",
      "Unique tokens in target (zh) vocabulary: 2313\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)\n",
    "print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (zh) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['假设', '中间', '夹', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', '着', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', '一个', '名字']\n",
      "['there', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', 'is', 'a', 'card', 'name', '<', 'x', 'b', 'p', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'r', 'o', 'n', 'g', 'e', 's', 't', ' ', 'o', 'f', ' ', 'a', 'l', 'l', '>', '.']\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import tokenize_en, tokenize_zh\n",
    "\n",
    "print(tokenize_zh('假设中间夹<xbp, the strongest of all>着<xbp, the strongest of all>一个名字'))\n",
    "print(tokenize_en('there <xbp, the strongest of all> is a card name <xbp, the strongest of all>.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 128]\n",
      "\t[.src]:('[torch.LongTensor of size 22x128]', '[torch.LongTensor of size 128]')\n",
      "\t[.trg]:[torch.LongTensor of size 39x128]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)\n",
    "\n",
    "tmp = next(iter(train_iterator))\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model4.definition import Encoder, Attention, Decoder, Seq2Seq\n",
    "from models.model4.train import init_weights, train, evaluate\n",
    "from utils import count_parameters, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,553,545 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "train_loop(model, optimizer, criterion, train, evaluate,\n",
    "           train_iterator, valid_iterator, \n",
    "           save_path='result/', file_name='model4-rule-v1.pt', load_before_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.translate import Translator\n",
    "from models.model4.definition import beam_search\n",
    "model.load_state_dict(torch.load('model4-rule-v1.pt', map_location=torch.device(device)))\n",
    "T = Translator(SRC, TRG, model, device, beam_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['当', '<', 'p', 'r', 'o', 't', 'o', 't', 'y', 'p', 'e', '>', '征列', '生物', '时', '，', '抓', '一', '张', '生物', '，', '抓', '一', '张牌', '。', '<eos>']\n",
      "['当', '<', '<', 'r', 'r', 'o', 't', 'o', 't', 'y', 'p', 'e', '>', '征列', '生物', '时', '，', '抓', '一', '张', '生物', '，', '抓', '一', '张牌', '。', '<eos>']\n",
      "['当', '<', 'p', 'r', 'o', 't', 'o', 't', 'y', 'p', 'e', '>', '征列', '生物', '时', '，', '抓', '一', '张', '生物', '，', '抓', '抓', '一', '张牌', '。', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "data = 'When ever <prototype> enlist a creature, draw a card.'\n",
    "ret, prob, att = T.translate_with_att(data, max_len=100)\n",
    "print(*ret[:3], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 352\n",
      "src: [spells your opponents cast that target < i c e f a l l   r e g e n t > cost { 2 } more to cast . ] trg = [由对手施放且以<icefall regent>为目标的咒语增加{2}来施放。]\n",
      "对手施放之以<icefall regent>为目标的咒语增加{2}来施放。<eos> \t[probability: 0.16734]\n",
      "对手施放之以<icefall regent>为目标的咒语增加{2}来使用。<eos> \t[probability: 0.01427]\n",
      "对手施放之以<icefall regent>为目标为目标的咒语增加{2}来施放。<eos> \t[probability: 0.00839]\n",
      "\n",
      "src: [each clashing player reveals the top card of their library , then puts that card on the top or bottom . ] trg = [参与比点的牌手各展示其牌库顶牌，然后将该牌置于牌库顶部或底部。]\n",
      "参与比点的牌手各展示其牌库顶牌，然后将该牌置于底部底部底部底部。<eos> \t[probability: 0.30383]\n",
      "参与比点的牌手各展示其牌库顶牌，然后将该牌置于底部底部底部底部底部。<eos> \t[probability: 0.11974]\n",
      "参与比点的牌手各展示其牌库顶牌，然后将该牌置于底部底部底部底部。底部。<eos> \t[probability: 0.09725]\n",
      "\n",
      "src: [as this creature enters the battlefield , an opponent of your choice may put two + 1 / + 1 counters on it . ] trg = [于此生物进战场时，选择一位对手，他可以在其上放置两个+1/+1指示物。]\n",
      "于此生物进战场时，选择一位对手，他可以在其上放置两个+1/+1指示物。<eos> \t[probability: 0.62496]\n",
      "于此生物进时，选择一位对手，他可以在其上放置两个+1/+1指示物。<eos> \t[probability: 0.03789]\n",
      "于此生物进战场时，选择一位对手，他可以可以在其上放置两个+1/+1指示物。<eos> \t[probability: 0.02680]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import show_samples\n",
    "long_data = [x for x in test_data.examples if len(x.src) > 20]\n",
    "print(f'Number of samples: {len(long_data)}')\n",
    "show_samples(long_data, T, n=3, beam_size=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
